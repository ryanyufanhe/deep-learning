{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# 彩色图片分类"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 加载相关库"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "import tensorflow as tf\n",
                "from tensorflow.keras import datasets, layers, optimizers\n",
                "import matplotlib.pyplot as plt"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Init Plugin\n",
                        "Init Graph Optimizer\n",
                        "Init Kernel\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 导入数据"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "(train_x, train_y), (test_x, test_y) = datasets.cifar10.load_data()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 归一化"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "train_x, test_x = train_x / 255.0, test_x / 255.0\n",
                "\n",
                "print(\"train_data: \", train_x.shape, train_y.shape)\n",
                "print(\"test_data: \", test_x.shape, test_y.shape)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "train_data:  (50000, 32, 32, 3) (50000, 1)\n",
                        "test_data:  (10000, 32, 32, 3) (10000, 1)\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 建模"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "class CNN(tf.keras.Model):\n",
                "    def __init__(self):\n",
                "        super(CNN, self).__init__()\n",
                "        self.conv_1 = layers.Conv2D(32, (3, 3), activation='relu')\n",
                "        self.conv_2 = layers.Conv2D(64, (3, 3), activation='relu')\n",
                "        self.conv_3 = layers.Conv2D(64, (3, 3), activation='relu')\n",
                "\n",
                "        self.max_pooling = layers.MaxPooling2D((2, 2))\n",
                "        self.flatten = layers.Flatten()\n",
                "        \n",
                "        self.linear_1 = layers.Dense(64, activation='relu')\n",
                "        self.linear_2 = layers.Dense(10)\n",
                "\n",
                "    def call(self, x):\n",
                "        x = self.conv_1(x)\n",
                "        x = self.max_pooling(x)\n",
                "        x = self.conv_2(x)\n",
                "        x = self.max_pooling(x)\n",
                "        x = self.conv_3(x)\n",
                "        x = self.flatten(x)\n",
                "        x = self.linear_1(x)\n",
                "        x = self.linear_2(x)\n",
                "        return x\n",
                "\n",
                "model = CNN()"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Metal device set to: Apple M1\n",
                        "\n",
                        "systemMemory: 8.00 GB\n",
                        "maxCacheSize: 2.67 GB\n",
                        "\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "2021-08-26 23:05:53.923106: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
                        "2021-08-26 23:05:53.923550: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "train_x = tf.convert_to_tensor(train_x, dtype=tf.float32)\n",
                "test_x = tf.convert_to_tensor(test_x, dtype=tf.float32)\n",
                "\n",
                "train_y = tf.convert_to_tensor(train_y)\n",
                "test_y = tf.convert_to_tensor(test_y)\n",
                "\n",
                "\n",
                "train_db = tf.data.Dataset.from_tensor_slices((train_x, train_y)).batch(100)\n",
                "test_db = tf.data.Dataset.from_tensor_slices((test_x, test_y)).batch(100)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "source": [
                "loss_function = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
                "optimizer = optimizers.Adam()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "source": [
                "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
                "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
                "\n",
                "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
                "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "source": [
                "@tf.function\n",
                "def train_step(images, labels):\n",
                "    with tf.GradientTape() as tape:\n",
                "        prediction = model(images)\n",
                "        loss = loss_function(labels, prediction)\n",
                "    gradients = tape.gradient(loss, model.trainable_variables)\n",
                "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
                "\n",
                "    train_loss(loss)\n",
                "    train_accuracy(labels, prediction)\n",
                "\n",
                "\n",
                "@tf.function\n",
                "def test_step(images, labels):\n",
                "  predictions = model(images)\n",
                "  t_loss = loss_function(labels, predictions)\n",
                "\n",
                "  test_loss(t_loss)\n",
                "  test_accuracy(labels, predictions)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "source": [
                "EPOCHS = 10\n",
                "\n",
                "\n",
                "for epoch in range(EPOCHS):\n",
                "    train_loss.reset_states()\n",
                "    train_accuracy.reset_states()\n",
                "    test_loss.reset_states()\n",
                "    test_accuracy.reset_states()\n",
                "\n",
                "    for images, labels in train_db:\n",
                "        train_step(images, labels)\n",
                "\n",
                "    for test_images, test_labels in test_db:\n",
                "        test_step(test_images, test_labels)\n",
                "\n",
                "    template = 'Epoch {}, Loss: {}, Accuracy: {}%, Test Loss: {}, Test Accuracy: {}%'\n",
                "        \n",
                "    print(template.format(epoch + 1,\n",
                "                          train_loss.result(), \n",
                "                          train_accuracy.result() * 100,\n",
                "                          test_loss.result(),\n",
                "                          test_accuracy.result() * 100))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "2021-08-26 23:05:55.178815: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
                        "2021-08-26 23:05:55.181161: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
                        "2021-08-26 23:05:55.181641: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
                        "2021-08-26 23:06:01.728387: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Epoch 1, Loss: 1.6293104887008667, Accuracy: 40.39800262451172%, Test Loss: 1.38679838180542, Test Accuracy: 50.51000213623047%\n",
                        "Epoch 2, Loss: 1.27566659450531, Accuracy: 54.28800582885742%, Test Loss: 1.2001688480377197, Test Accuracy: 56.95000457763672%\n",
                        "Epoch 3, Loss: 1.1287208795547485, Accuracy: 60.2180061340332%, Test Loss: 1.1472587585449219, Test Accuracy: 59.910003662109375%\n",
                        "Epoch 4, Loss: 1.0380208492279053, Accuracy: 63.716007232666016%, Test Loss: 1.0259485244750977, Test Accuracy: 64.29000854492188%\n",
                        "Epoch 5, Loss: 0.9613401889801025, Accuracy: 66.56000518798828%, Test Loss: 0.9838595390319824, Test Accuracy: 65.93000030517578%\n",
                        "Epoch 6, Loss: 0.8983980417251587, Accuracy: 68.73200225830078%, Test Loss: 0.949745237827301, Test Accuracy: 67.2300033569336%\n",
                        "Epoch 7, Loss: 0.8454487919807434, Accuracy: 70.5780029296875%, Test Loss: 0.9266660809516907, Test Accuracy: 68.16000366210938%\n",
                        "Epoch 8, Loss: 0.8037283420562744, Accuracy: 72.16600036621094%, Test Loss: 0.8999237418174744, Test Accuracy: 68.94000244140625%\n",
                        "Epoch 9, Loss: 0.766410768032074, Accuracy: 73.47200775146484%, Test Loss: 0.8756957054138184, Test Accuracy: 69.9800033569336%\n",
                        "Epoch 10, Loss: 0.7309417128562927, Accuracy: 74.66000366210938%, Test Loss: 0.869552731513977, Test Accuracy: 70.16000366210938%\n"
                    ]
                }
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.8.10",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.8.10 64-bit ('ai': conda)"
        },
        "interpreter": {
            "hash": "0b206347cbf1c849f0a4287732bf2bb6386e9e4f72ceb5a6d82fe819f05f0e07"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}