{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 手写数字识别"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 加载相关库"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, optimizers\n",
    "import numpy as np"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 加载相关数据"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "(train_data, test_data) = datasets.mnist.load_data()\n",
    "print('train_dataset: ', train_data[0].shape, train_data[1].shape)\n",
    "print('test_dataset: ', test_data[0].shape, test_data[1].shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train_dataset:  (60000, 28, 28) (60000,)\n",
      "test_dataset:  (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 建模"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### DNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "train_x = tf.convert_to_tensor(train_data[0], dtype=tf.float32) / 255. \n",
    "test_x = tf.convert_to_tensor(test_data[0], dtype=tf.float32) / 255.\n",
    "\n",
    "train_y = tf.convert_to_tensor(train_data[1])\n",
    "test_y = tf.convert_to_tensor(test_data[1], dtype=tf.float32)\n",
    "\n",
    "train_x = tf.reshape(train_x, (-1, 28*28))\n",
    "test_x = tf.reshape(test_x, (-1, 28*28))\n",
    "\n",
    "\n",
    "train_db = tf.data.Dataset.from_tensor_slices((train_x, train_y)).batch(100)\n",
    "test_db = tf.data.Dataset.from_tensor_slices((test_x, test_y)).batch(100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-08-26 17:10:20.718965: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-08-26 17:10:20.719082: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "class DNN(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__()\n",
    "        self.linear_1 = layers.Dense(512, activation='relu')\n",
    "        self.linear_2 = layers.Dense(256, activation='relu')\n",
    "        self.linear_3 = layers.Dense(10)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.linear_1(x)\n",
    "        x = self.linear_2(x)\n",
    "        x = self.linear_3(x)\n",
    "        return x\n",
    "\n",
    "model = DNN()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "loss_function = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = optimizers.Adam()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        prediction = model(images)\n",
    "        loss = loss_function(labels, prediction)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, prediction)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "  predictions = model(images)\n",
    "  t_loss = loss_function(labels, predictions)\n",
    "\n",
    "  test_loss(t_loss)\n",
    "  test_accuracy(labels, predictions)\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "\n",
    "    for images, labels in train_db:\n",
    "        train_step(images, labels)\n",
    "\n",
    "    for test_images, test_labels in test_db:\n",
    "        test_step(test_images, test_labels)\n",
    "\n",
    "    template = 'Epoch {}, Loss: {}, Accuracy: {}%, Test Loss: {}, Test Accuracy: {}%'\n",
    "        \n",
    "    print(template.format(epoch + 1,\n",
    "                          train_loss.result(), \n",
    "                          train_accuracy.result() * 100,\n",
    "                          test_loss.result(),\n",
    "                          test_accuracy.result() * 100))\n",
    "    \n",
    "        "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-08-26 17:10:21.325233: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-08-26 17:10:21.326354: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2021-08-26 17:10:21.326424: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-08-26 17:10:24.362538: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1, Loss: 0.23318937420845032, Accuracy: 93.05000305175781%, Test Loss: 0.11252956837415695, Test Accuracy: 96.3800048828125%\n",
      "Epoch 2, Loss: 0.08812576532363892, Accuracy: 97.30333709716797%, Test Loss: 0.12395542860031128, Test Accuracy: 95.9800033569336%\n",
      "Epoch 3, Loss: 0.05420693755149841, Accuracy: 98.36833190917969%, Test Loss: 0.2999819219112396, Test Accuracy: 92.72000122070312%\n",
      "Epoch 4, Loss: 0.036737002432346344, Accuracy: 98.83333587646484%, Test Loss: 0.10690704733133316, Test Accuracy: 96.99000549316406%\n",
      "Epoch 5, Loss: 0.028400951996445656, Accuracy: 99.0999984741211%, Test Loss: 0.11166983097791672, Test Accuracy: 97.34000396728516%\n",
      "Epoch 6, Loss: 0.02575034275650978, Accuracy: 99.17666625976562%, Test Loss: 0.08645763993263245, Test Accuracy: 97.79000091552734%\n",
      "Epoch 7, Loss: 0.017862997949123383, Accuracy: 99.37833404541016%, Test Loss: 0.08414957672357559, Test Accuracy: 97.9000015258789%\n",
      "Epoch 8, Loss: 0.015828153118491173, Accuracy: 99.4566650390625%, Test Loss: 0.11137963086366653, Test Accuracy: 97.33000183105469%\n",
      "Epoch 9, Loss: 0.01817125827074051, Accuracy: 99.40499877929688%, Test Loss: 0.10742168873548508, Test Accuracy: 97.5300064086914%\n",
      "Epoch 10, Loss: 0.015686996281147003, Accuracy: 99.49832916259766%, Test Loss: 0.09253324568271637, Test Accuracy: 98.04000091552734%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"dnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  401920    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  131328    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  2570      \n",
      "=================================================================\n",
      "Total params: 535,818\n",
      "Trainable params: 535,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "train_x = tf.convert_to_tensor(train_data[0], dtype=tf.float32) / 255. \n",
    "test_x = tf.convert_to_tensor(test_data[0], dtype=tf.float32) / 255.\n",
    "\n",
    "train_y = tf.convert_to_tensor(train_data[1])\n",
    "test_y = tf.convert_to_tensor(test_data[1], dtype=tf.float32)\n",
    "\n",
    "train_x = tf.reshape(train_x, (-1, 28, 28, 1))\n",
    "test_x = tf.reshape(test_x, (-1, 28, 28, 1))\n",
    "\n",
    "\n",
    "train_db = tf.data.Dataset.from_tensor_slices((train_x, train_y)).batch(100)\n",
    "test_db = tf.data.Dataset.from_tensor_slices((test_x, test_y)).batch(100)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "class CNN(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_1 = layers.Conv2D(32, (3, 3), activation='relu')\n",
    "        self.conv_2 = layers.Conv2D(64, (3, 3), activation='relu')\n",
    "        self.conv_3 = layers.Conv2D(64, (3, 3), activation='relu')\n",
    "        self.linear_1 = layers.Dense(64, activation='relu')\n",
    "        self.linear_2 = layers.Dense(10)\n",
    "        self.pooling = layers.MaxPool2D((2, 2))\n",
    "        self.flatten = layers.Flatten()\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv_1(input)\n",
    "        x = self.pooling(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.pooling(x)\n",
    "        x = self.conv_3(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear_1(x)\n",
    "        x = self.linear_2(x)\n",
    "        return x\n",
    "\n",
    "model = CNN()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "model = CNN()\n",
    "\n",
    "\n",
    "# optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "# loss_function = tf.keras.losses.sparse_categorical_crossentropy\n",
    "\n",
    "# y_pred = model(train_x[:100])\n",
    "# print(y_pred)\n",
    "\n",
    "# with tf.GradientTape() as tape:\n",
    "    # y_pred = model(train_x)\n",
    "    # print(y_pred.shape, train_y.shape)\n",
    "    # loss = loss_function(y_pred, train_y)\n",
    "    # print(loss)\n",
    "\n",
    "\n",
    "# for i in range(10):\n",
    "    # with tf.GradientTape() as tape:\n",
    "    #     y_pred = model(train_x)\n",
    "    #     print(y_pred)\n",
    "        # loss = tf.reduce_mean(loss_function(y_pred, train_y))\n",
    "        # print(loss)\n",
    "    # grads = tape.gradient(loss, model.variables)\n",
    "    # optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))\n",
    "\n",
    "\n",
    "\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#               metrics=['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "history = model.fit(train_x, train_y, epochs=10)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/y5/6xfh1jfd0xs0c2ybtgl5t7gr0000gn/T/ipykernel_38237/4160162112.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/ai/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1103\u001b[0m     \u001b[0;31m# Legacy graph support is contained in `training_v1.Model`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m     \u001b[0mversion_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisallow_legacy_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_compile_was_called\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_call_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m     \u001b[0m_disallow_inside_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ai/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2691\u001b[0m     \u001b[0;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2693\u001b[0;31m       raise RuntimeError('You must compile your model before '\n\u001b[0m\u001b[1;32m   2694\u001b[0m                          \u001b[0;34m'training/testing. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m                          'Use `model.compile(optimizer, loss)`.')\n",
      "\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pred = np.argmax(model.predict(test_x), axis=-1).reshape(-1, 1)\n",
    "pred"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [0],\n",
       "       [9],\n",
       "       ...,\n",
       "       [3],\n",
       "       [9],\n",
       "       [2]])"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 输出数据"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "image_id = np.array(range(1, 28000 + 1)).reshape(-1, 1)\n",
    "result = pd.DataFrame(data=np.concatenate([image_id, pred], axis=1), columns=['ImageId', 'Label'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "result.to_csv('submission.csv', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('ai': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "interpreter": {
   "hash": "0b206347cbf1c849f0a4287732bf2bb6386e9e4f72ceb5a6d82fe819f05f0e07"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}